{
  "_comment": "Qwen2.5-32B QLoRA Expert Models Deployment Configuration",
  
  "_model_ids": "Model IDs on ModelScope",
  "base_model_id": "Qwen/Qwen2.5-32B-Instruct-AWQ",
  "expert_a_id": "GaryLeenene/qwen25-32b-expert-a-qlora",
  "expert_b_id": "GaryLeenene/qwen25-32b-expert-b-qlora",
  
  "_model_paths": "Local paths for downloaded models",
  "base_model_path": "./models/base_model",
  "expert_a_path": "./models/expert_a",
  "expert_b_path": "./models/expert_b",
  
  "_vllm_config": "vLLM configuration for inference",
  "tensor_parallel_size": 1,
  "max_model_len": 4096,
  "gpu_memory_utilization": 0.85,
  "dtype": "float16",
  "quantization": "awq",
  
  "_inference_config": "Generation parameters",
  "temperature": 0.7,
  "top_p": 0.9,
  "top_k": 50,
  "max_tokens": 1024,
  "repetition_penalty": 1.1,
  
  "_hardware_config": "Hardware-specific configuration for RTX 4080S 32GB",
  "device": "cuda:0",
  "load_in_4bit": true,
  "use_triton": true,
  "inject_fused_attention": true,
  "inject_fused_mlp": true,
  
  "_logging_config": "Logging configuration",
  "log_level": "INFO",
  "log_dir": "./logs",
  "save_logs": true
}
